{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fKzYr96PfTUK"
      },
      "source": [
        "# Convolutional Neural Networks with CIFAR-10 Dataset\n",
        "\n",
        "## Objective\n",
        "In this exercise, you will:\n",
        "1. Utilize callback functions to halt training when a certain accuracy threshold is met.\n",
        "2. Integrate convolutional and MaxPooling layers into a neural network to enhance image classification accuracy.\n",
        "3. Grasp and demonstrate the benefits of convolution and MaxPooling in image classification tasks.\n",
        "\n",
        "---\n",
        "\n",
        "## Step 1: Import Libraries\n",
        "Let's start by importing the necessary libraries.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "y1JnJf_EfTUM"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.datasets import cifar10\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q_MybmDUfTUN"
      },
      "source": [
        "---\n",
        "\n",
        "## Step 2: Load and Preprocess the Data\n",
        "We'll load the CIFAR-10 dataset and then normalize the pixel values.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "-JfnMPpVfTUN",
        "outputId": "a7125e14-5eaa-464f-a39b-5a0df06e048b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train images shape: (50000, 32, 32, 3)\n",
            "Train labels shape: (50000, 1)\n",
            "Test images shape: (10000, 32, 32, 3)\n",
            "Test labels shape: (10000, 1)\n"
          ]
        }
      ],
      "source": [
        "# Load the CIFAR-10 dataset\n",
        "(train_images, train_labels), (test_images, test_labels) = tf.keras.datasets.cifar10.load_data()\n",
        "\n",
        "# TODO Normalize the pixel values\n",
        "\n",
        "train_images = train_images / 255.0\n",
        "test_images = test_images / 255.0\n",
        "\n",
        "# Display the shape of the loaded data\n",
        "print(\"Train images shape:\", train_images.shape)\n",
        "print(\"Train labels shape:\", train_labels.shape)\n",
        "print(\"Test images shape:\", test_images.shape)\n",
        "print(\"Test labels shape:\", test_labels.shape)\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vRhR-zKDfTUO"
      },
      "source": [
        "---\n",
        "\n",
        "## Step 3: Visualize the Data\n",
        "Show some samples from the CIFAR-10 dataset.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tQ3fsJ_zfTUO"
      },
      "outputs": [],
      "source": [
        "class_names = ['airplane', 'automobile', 'bird', 'cat', 'deer',\n",
        "               'dog', 'frog', 'horse', 'ship', 'truck']\n",
        "\n",
        "plt.figure(figsize=(10,10))\n",
        "for i in range(25):\n",
        "    plt.subplot(5,5,i+1)\n",
        "    plt.xticks([])\n",
        "    plt.yticks([])\n",
        "    plt.grid(False)\n",
        "    plt.imshow(train_images[i])\n",
        "    # The CIFAR labels happen to be arrays, which is why you need the extra index\n",
        "    plt.xlabel(class_names[train_labels[i][0]])\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w_14SV8mfTUO"
      },
      "source": [
        "---\n",
        "\n",
        "## Step 4: Define a Callback\n",
        "Create a callback to monitor the model's accuracy and halt training when a specified accuracy is achieved.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "vZ4TARyLfTUO"
      },
      "outputs": [],
      "source": [
        "# TODO define a callback that interrupts training after an accuracy of 90% is reached\n",
        "class AccuracyCallback(tf.keras.callbacks.Callback):\n",
        "    def on_epoch_end(self, epoch, logs={}):\n",
        "      if (logs.get('accuracy') > 0.9):\n",
        "        print(\"\\nAccuracy of 90% reached - stopping training.\\n\")\n",
        "        self.model.stop_training = True\n",
        "\n",
        "accuracy_callback = AccuracyCallback()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1szeC55nfTUO"
      },
      "source": [
        "---\n",
        "\n",
        "## Step 5: Build a Convolutional Neural Network\n",
        "Construct a neural network that incorporates convolutional and MaxPooling layers.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iPjLEz9ufTUO"
      },
      "outputs": [],
      "source": [
        "model = tf.keras.models.Sequential([\n",
        "  tf.keras.layers.Conv2D(64, (3,3), activation='relu', input_shape=(32, 32, 3)),\n",
        "  tf.keras.layers.MaxPooling2D(2, 2),\n",
        "  tf.keras.layers.Conv2D(64, (3,3), activation='relu'),\n",
        "  tf.keras.layers.MaxPooling2D(2,2),\n",
        "  tf.keras.layers.Flatten(),\n",
        "  tf.keras.layers.Dense(512, activation=tf.nn.relu),\n",
        "  tf.keras.layers.Dense(10, activation=tf.nn.softmax)\n",
        "])\n",
        "\n",
        "# Compile the model\n",
        "model.compile(optimizer=tf.optimizers.Adam(),\n",
        "              loss='sparse_categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "model.summary()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MqwweckZfTUP"
      },
      "source": [
        "---\n",
        "\n",
        "## Step 6: Train the Model\n",
        "Train the model using the training data and your callback function\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "rYIFg86hfTUP",
        "outputId": "777f5944-8617-4752-ea93-30e071fd03a0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "1563/1563 [==============================] - 133s 84ms/step - loss: 1.3993 - accuracy: 0.5003\n",
            "Epoch 2/10\n",
            "1563/1563 [==============================] - 130s 83ms/step - loss: 1.0258 - accuracy: 0.6375\n",
            "Epoch 3/10\n",
            "1563/1563 [==============================] - 125s 80ms/step - loss: 0.8416 - accuracy: 0.7070\n",
            "Epoch 4/10\n",
            "1563/1563 [==============================] - 126s 81ms/step - loss: 0.7022 - accuracy: 0.7559\n",
            "Epoch 5/10\n",
            "1563/1563 [==============================] - 124s 79ms/step - loss: 0.5698 - accuracy: 0.7999\n",
            "Epoch 6/10\n",
            "1563/1563 [==============================] - 126s 80ms/step - loss: 0.4452 - accuracy: 0.8439\n",
            "Epoch 7/10\n",
            "1563/1563 [==============================] - 123s 79ms/step - loss: 0.3317 - accuracy: 0.8853\n",
            "Epoch 8/10\n",
            "1562/1563 [============================>.] - ETA: 0s - loss: 0.2463 - accuracy: 0.9160\n",
            "Accuracy of 90% reached - stopping training.\n",
            "\n",
            "1563/1563 [==============================] - 126s 80ms/step - loss: 0.2464 - accuracy: 0.9160\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.History at 0x7bac37825d20>"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ],
      "source": [
        "model.fit(train_images, train_labels, epochs=10, callbacks=[accuracy_callback])\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M6FyDvwNfTUP"
      },
      "source": [
        "---\n",
        "\n",
        "## Step 7: Evaluate the Model\n",
        "Assess the model using the test data.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ET29o1yTfTUP"
      },
      "outputs": [],
      "source": [
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6iAi2lRofTUP"
      },
      "source": [
        "---\n",
        "\n",
        "## Step 8 (Optional): Visualizing the Advantages of Convolution and MaxPooling\n",
        "Demonstrate the benefits of convolution and MaxPooling. For this, we can extract the outputs from intermediate layers and visualize them. Play around with this to to find out what the model learns.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "269ioTACfTUQ",
        "outputId": "9a29d438-026f-4c9e-c8fd-b812e0a9bad3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 423
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 160ms/step\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "# Extracting outputs from our layers\n",
        "layer_outputs = [layer.output for layer in model.layers]\n",
        "activation_model = tf.keras.models.Model(inputs=model.input, outputs=layer_outputs)\n",
        "\n",
        "# For the first image in the training set\n",
        "img = train_images[0]\n",
        "img = np.expand_dims(img, axis=0)\n",
        "\n",
        "# Get the feature maps\n",
        "activations = activation_model.predict(img)\n",
        "\n",
        "# Visualizing the fourth channel of the output from the first layer (convolution)\n",
        "plt.imshow(activations[0][0, :, :, 4], cmap='inferno')\n",
        "plt.axis('off')\n",
        "plt.show()\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": ".ve_tensorflow_course",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.10"
    },
    "orig_nbformat": 4,
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}